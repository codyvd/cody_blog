[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cody’s Blog",
    "section": "",
    "text": "Hidden Markov Modeling\n\n\n\n\n\n\n\nr\n\n\nsimulations\n\n\nbayesian\n\n\nhmm\n\n\n\n\nbeginner tutorial on Hidden Markov Modeling.\n\n\n\n\n\n\nMay 17, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/hmm/index.html",
    "href": "posts/hmm/index.html",
    "title": "Hidden Markov Modeling",
    "section": "",
    "text": "Motivation: Hidden Markov Models are useful when you have a sequence of observed data that is a function of unobservable states which change over time. You may be interested in estimating the state time-series which gave rise to the observations.\nAs an example: perhaps your shopping habits change as a function of your current mood. A researcher is unable to directly observe your mood at any given moment, but they are able to observe your shopping habits over time. Perhaps you shop more when you are in a happy mood compared to a sad mood. By modeling the data using a HMM, the researcher can obtain estimates of the unobservable states and how they may be changing over time.\n\n\n\nMoods and Shopping\n\n\nMore formally, Hidden Markov Models are models that include unobservable (i.e., hidden) states (\\(x_1, x_2, ...x_n\\)) which can transition to one another over time. Each state is associated with an emission model (\\(p(y_t|x_t,\\theta)\\); where \\(\\theta\\) are the parameters of the emission model) that link unobservable states (\\(x_t\\)) to observations (\\(y_t\\)). In particular, state transitions are assumed to satisfy the Markov property where the state model is associated with a set of parameters (\\(\\omega\\)) consisting of transition probabilities (\\(\\nu\\)) and initial state probabilities (\\(\\pi\\)). In this tutorial we explore discrete state and discrete time HMM models.\nLooking at the diagram:  The initial state probabilities (\\(\\pi = [0.6, 0.4]\\)) are denoted by the arrows from the very top pointing towards “Rainy” and “Sunny”. The transition probabilities are the arrows between the states (note: states can transition to themselves). Here the emission model is a multionomial distribution over the observable states (each hidden state has its own multinomial probability parameters) which are walking, shopping, and cleaning."
  },
  {
    "objectID": "posts/hmm/index.html#example-switching-noisy-normal-distributions",
    "href": "posts/hmm/index.html#example-switching-noisy-normal-distributions",
    "title": "Hidden Markov Modeling",
    "section": "Example: Switching Noisy Normal Distributions",
    "text": "Example: Switching Noisy Normal Distributions\n\n\nCode\nlibrary(tidyverse)\n\n\nHidden Markov Models can be viewed as an extension of mixture models where the mixture components can switch over time (i.e., the hidden state changes over time).\nIn this example, I will generate data from two normal distributions (each with different means, but both with variance of 1 for simplicity), where the distribution I am sampling from will change over time (based on the transition probabilities between the states). From this simulated data, I will then fit a HMM model to see how accurately it can estimate which distribution is being sampled from at each time point.\nTo begin, here I first depict the two normal distributions which I will sample from:\n\n\nCode\np <- ggplot(data.frame(x = c(0, 8)), aes(x)) + \n  stat_function(fun = dnorm, args = list(mean = 3, sd = 1), col='red') +\n  stat_function(fun = dnorm, args = list(mean = 5, sd = 1), col='blue') + \n  ggtitle(\"Normal Distributions: State 1 = Red, State 2 = Blue\")\n\np\n\n\n\n\n\n\n\n\n\nWe see that there is overlap between the distributions, this means that estimation of which state the sampled observations come from will have uncertainty.\nHere I generate a sequence of observations, starting with an initial probability distribution of \\(\\pi = [0.5, 0.5]\\), and a probability transition matrix of: \\(\\nu = [0.9,0.1;0.1,0.9]\\) (stay probability of 0.9 for both states, and switch probability of 0.1 for both states).\n\n\nCode\nset.seed(518) #for reproducability\n\nn <- 100  # numobs\nm <- 2    # numstates\n\nmu <- c(3,5) #means of normal distribution\nsig <- c(1,1) #st devs; together these are theta, underlying parameters\n\nnu <- rbind(c(0.9,0.1),c(0.1,0.9)) #transition probability matrix\nmarg <- c(0.5,0.5) #this is pi, the initial distribution\nX.norm <- rep(NA,n)\nY.norm <- rep(NA,n)\n\nX.norm[1] <- 1\nY.norm[1] <- rnorm(1,mu[1],sig[1])\nfor (i in 2:n){\n    u <- runif(1)\n    if (X.norm[i-1] == 1){\n        X.norm[i] <- ifelse(u > nu[1,1],2,1)\n    }\n    if (X.norm[i-1] == 2){\n        X.norm[i] <- ifelse(u > nu[2,2],1,2)\n    }\n    if (X.norm[i]==1){\n        Y.norm[i] <- rnorm(1,mu[1],sig[1])\n    }\n    if (X.norm[i]==2){\n        Y.norm[i] <- rnorm(1,mu[2],sig[2])\n    }\n}\n\npar(mfrow=c(2,1))\nplot(1:n,Y.norm,pch=19,ylab= \"y\", xlab = \"time\")\nytick <- c(1,2)\nplot(1:n,X.norm,pch=19, ylab = \"true state\", xlab = \"time\",yaxt = \"n\")\naxis(2, at = c(1,2))\n\n\n\n\n\n\n\n\n\nCode\n\ndata <- data.frame(Y.norm,X.norm)\n\n\nLook at the top row, we see that the observations fluctuate over time according to the true underlying state/distribution I sampled from. However, just looking at the observation we aren’t able to fully tell what the underlying state is for that time-point because the distributions aren’t entirely non-overlapping (this is especially salient at the time points where there are transitions from one state to the other).\nNow, let’s fit a HMM model to the data.\nThere are multiple ways to fit a HMM model to this data. One method to fit the data is called the “Viterbi Algorithm” which is a dynamic programming algorithm that recursively tries to calculate the optimal sequence of states (\\(\\hat{x}\\)) conditional on particular values of \\(\\theta\\) and \\(\\omega\\) (i.e., the state model and emission model parameters). Here I condition on the true parameters.\n\n\nCode\nset.seed(518) #for reproducability\n\nnorm.density <- function(obs,state){\n    if (state==1){\n        out <- dnorm(obs,mean=mu[1],sd=sig[1])\n    }\n    if (state==2){\n        out <- dnorm(obs,mean=mu[2],sd=sig[2])\n    }\n    out\n} #probability that given a state, that you got that observation y.\n\ndelta <- matrix(NA,nrow=n,ncol=m)\n## Initialization:\nfor (i in 1:m){\n    delta[1,i] <- marg[i]*norm.density(Y.norm[1],i)\n}\n## Recursion:\nfor (t in 2:n){\n    for (i in 1:m){\n        temp <- rep(NA,m)\n        for (j in 1:m){\n            temp[j] <- delta[t-1,j]*nu[j,i]*norm.density(Y.norm[t],i)\n        }\n        delta[t,i] <- max(temp)\n    }\n}\n## Tracing Back:\nXhat <- rep(NA,n)\nXhat[n] <- which(delta[n,]==max(delta[n,]))\nfor (t in (n-1):1){\n    temp <- rep(NA,m)\n    for (j in 1:m){\n        temp[j] <- delta[t,j]*nu[j,Xhat[t+1]]\n    }\n    Xhat[t] <- which(temp==max(temp))\n}\n\n\n### checking our inferred states\npar(mfrow=c(3,1))\nplot(1:n,Y.norm,pch=19,main=\"Observed Data\", ylab = \"observation\", xlab = \"time\")\nplot(1:n,X.norm,pch=19,main=\"True States\", ylab = \"true state\", xlab = \"time\",yaxt = \"n\")\naxis(2, at = c(1,2))\nplot(1:n,Xhat,pch=19,main=\"Viterbi Solution\", ylab = \"predicted state\", xlab = \"time\",yaxt = \"n\")\naxis(2, at = c(1,2))\nfor (i in 1:n){\n    if (Xhat[i] != X.norm[i]){\n        points(i,1.5,col=2,pch=19)\n    }\n}\n\n\n\n\n\n\n\n\n\nWe see that the Viterbi Solution is quite accurate most of the time, with errors (time points with errors indicated as red dots) occuring close to the timepoints where the model transitioned from one state to the next. However, there are cons:\n\nThe Viterbi algorithm is conditional on a set of parameters for both your emission model and state model, and in practice those are unknown.\nAdditionally, the Viterbi algorithm calculates the optimal path \\(\\hat{x}\\), which is only a point estimate given the observations. You may also be interested in estimating the uncertainty in \\(x\\) as well.\n\nThe second method I will present is a Bayesian approach leveraging the forward-backward combined with Gibbs Sampler. The forward-backward algorithm allows one to sample likely state paths (\\(x\\)) given the observations, and from these sampled paths we are able to employ the Gibbs Sampler (a Markov-Chain-Monte-Carlo algorithm) to obtain posterior distribution samples for our parameters of interest.\n\n\nCode\nset.seed(518) #for reproducability\n\nnumsamp <- 10000\nX.samp <- matrix(NA,nrow=numsamp,ncol=n)\nnu.samp <- matrix(NA,nrow=numsamp,ncol=m*m)\npi.samp <- matrix(NA,nrow=numsamp,ncol=m)\nmu.samp <- matrix(NA,nrow=numsamp,ncol=m)\n\ncurnu <- rbind(c(0.75,0.25),c(0.25,0.75)) #specify initial values\ncurpi <- c(0.5,0.5)\ncurmu <- c(2,4)\ncurX <- rep(NA,n)\n\nnorm.density <- function(obs,state,mu){\n    if (state==1){\n        out <- dnorm(obs,mean=mu[1],sd=1)\n    }\n    if (state==2){\n        out <- dnorm(obs,mean=mu[2],sd=1)\n    }\n    out\n}\n\nfor (iter in 1:numsamp){\n    #### Forward Algorithm ####\n    alpha <- matrix(NA,nrow=n,ncol=m)\n    for (i in 1:m){\n        alpha[1,i] <- curpi[i]*norm.density(Y.norm[1],i,curmu)\n    }\n    for (t in 2:n){\n        for (i in 1:m){\n            temp <- rep(NA,m)\n            for (j in 1:m){\n                temp[j] <- alpha[t-1,j]*curnu[j,i]*norm.density(Y.norm[t],i,curmu)\n            }\n            alpha[t,i] <- sum(temp)\n        }\n    }\n    #### Backwards Sampling ####\n    probvec <- alpha[n,]/sum(alpha[n,])\n    curX[n] <- sample(1:m,size=1,prob=probvec)\n    for (t in (n-1):1){\n        probvec <- rep(NA,m)\n        for (i in 1:m){\n            probvec[i] <- alpha[t,i]*curnu[i,curX[t+1]]\n        }\n        probvec <- probvec/sum(probvec)\n        curX[t] <- sample(1:m,size=1,prob=probvec)\n    }\n    #### Calculating N matrix ####\n    Nmat <- matrix(NA,nrow=m,ncol=m)\n    for (j in 1:m){\n        for (k in 1:m){\n            Nmat[j,k] <- 0\n            for (t in 2:n){\n                if (curX[t-1]==j && curX[t]==k){\n                    Nmat[j,k] <- Nmat[j,k] + 1\n                }\n            }\n        }   \n    }\n    #### Sampling Nu rows from Dirichlet (via Gammas) ####\n    for (j in 1:m){\n        for (k in 1:m){\n            curnu[j,k] <- rgamma(1,shape=(Nmat[j,k]+1),rate=1)\n        }\n        curnu[j,] <- curnu[j,]/sum(curnu[j,])\n    }\n    #### Calculating N vector ####\n    Nvec <- rep(NA,m)\n    for (j in 1:m){\n        Nvec[j] <- sum(curX==j)\n    }   \n    #### Sampling pi from Dirichlet (via Gammas) ####\n    for (j in 1:m){\n        curpi[j] <- rgamma(1,shape=(Nvec[j]+1),rate=1)\n    }\n    curpi<- curpi/sum(curpi)\n    #### Sampling means of emission model\n    for (j in 1:m){\n        curmean <- mean(Y.norm[curX==j])\n        curvar <- 1/sum(curX==j)\n        curmu[j] <- rnorm(1,curmean,sqrt(curvar))\n    }   \n    #### Storing parameter values           \n    X.samp[iter,] <- curX\n    nu.samp[iter,] <- as.vector(curnu)\n    pi.samp[iter,] <- curpi\n    mu.samp[iter,] <- curmu\n}\n\nX.samp1 <- X.samp\nnu.samp1 <- nu.samp\npi.samp1 <- pi.samp\nmu.samp1 <- mu.samp\n\n### re-running with different starting values\n\ncurnu <- rbind(c(0.5,0.5),c(0.5,0.5))\ncurpi <- c(0.25,0.75)\ncurmu <- c(1,5)\ncurX <- rep(NA,n)\n\nX.samp2 <- X.samp\nnu.samp2 <- nu.samp\npi.samp2 <- pi.samp\nmu.samp2 <- mu.samp\n\n# checking convergence using our multiple chains\n# par(mfrow=c(3,1))\nymin<-min(mu.samp1[,1],mu.samp2[,1])\nymax<-max(mu.samp1[,1],mu.samp2[,1])\n# plot(1:numsamp,mu.samp1[,1],type=\"l\",col=2,ylim=c(ymin,ymax))\n# lines(1:numsamp,mu.samp2[,1],col=3)\nymin<-min(mu.samp1[,2],mu.samp2[,2])\nymax<-max(mu.samp1[,2],mu.samp2[,2])\n# plot(1:numsamp,mu.samp1[,2],type=\"l\",col=2,ylim=c(ymin,ymax))\n# lines(1:numsamp,mu.samp2[,2],col=3)\nymin<-min(nu.samp1[,2],nu.samp2[,2])\nymax<-max(nu.samp1[,2],nu.samp2[,2])\n# plot(1:numsamp,nu.samp1[,2],type=\"l\",col=2,ylim=c(ymin,ymax))\n# lines(1:numsamp,nu.samp2[,2],col=3)\n\n### throwing out first 1000 samples as burnin and combine chains\npostburn <- 1001:numsamp\nX.samp <- rbind(X.samp1[postburn,],X.samp2[postburn,])\nmu.samp <- rbind(mu.samp1[postburn,],mu.samp2[postburn,])\nnu.samp <- rbind(nu.samp[postburn,],nu.samp2[postburn,])\npi.samp <- rbind(pi.samp1[postburn,],pi.samp2[postburn,])\n\n### checking acf\nacf(mu.samp[,1], plot=FALSE)\nacf(mu.samp[,2], plot=FALSE)\nacf(nu.samp[,1], plot=FALSE)\nacf(nu.samp[,2], plot=FALSE)\nacf(nu.samp[,3], plot=FALSE)\nacf(nu.samp[,4], plot=FALSE)\nacf(pi.samp[,1], plot=FALSE)\nacf(pi.samp[,2], plot=FALSE)\n\n### thinning\ntemp <- 5*(c(1:(length(mu.samp[,1])/5)))\n\nX.samp.thin <- X.samp[temp,]\nmu.samp.thin <- mu.samp[temp,]\nnu.samp.thin <- nu.samp[temp,]\npi.samp.thin <- pi.samp[temp,]\n\n### checking acf\nacf(mu.samp.thin[,1], plot=FALSE)\nacf(mu.samp.thin[,2], plot=FALSE)\nacf(nu.samp.thin[,1], plot=FALSE)\nacf(nu.samp.thin[,2], plot=FALSE)\nacf(nu.samp.thin[,3], plot=FALSE)\nacf(nu.samp.thin[,4], plot=FALSE)\nacf(pi.samp.thin[,1], plot=FALSE)\nacf(pi.samp.thin[,2], plot=FALSE)\n\nX.final <- X.samp.thin\nmu.final <- mu.samp.thin\nnu.final <- nu.samp.thin\npi.final <- pi.samp.thin\n\n\n### calculating posterior probabilities of hidden states\nX.postprob <- rep(NA,n)\nfor (j in 1:n){  \n    X.postprob[j] <- sum(X.final[,j]==2)/length(X.final[,1])\n}\n\n\n\n\nCode\n### checking our inferred states\npar(mfrow=c(2,1))\nplot(1:n,Y.norm,pch=19,main=\"Observed Data\", ylab = \"observation\", xlab = \"time\")\nplot(1:n,Xhat,pch=19,main=\"Viterbi Solution\", ylab = \"predicted state\", xlab = \"time\",yaxt = \"n\")\naxis(2, at = c(1,2))\nfor (i in 1:n){\n    if (Xhat[i] != X.norm[i]){\n        points(i,1.5,col=2,pch=19)\n    }\n}\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow=c(2,1))\nplot(1:n,X.postprob,col=4,pch=19,main=\"Posterior Probability\", ylab = \"p(x=2)\", xlab =\"time\", yaxt = \"n\")\naxis(2, at = c(0, 1))\nplot(1:n,X.norm,pch=19,main=\"True States\", ylab = \"true state\", xlab = \"time\",yaxt = \"n\")\naxis(2, at = c(1,2))\n\n\n\n\n\n\n\n\n\nLooking at the the posterior distribution samples, we see that the model is confident (i.e., probabilities close to 1 or 0) for segments where the state is stable, and less confident for points where there is a transition between states. Critically, we are now able to quantify how uncertain the model is using these posterior distribution samples."
  },
  {
    "objectID": "posts/hmm/index.html#conclusions",
    "href": "posts/hmm/index.html#conclusions",
    "title": "Hidden Markov Modeling",
    "section": "Conclusions",
    "text": "Conclusions\nI presented a simplified example analyzing data generated from two noisy normal distributions, but HMM are quite versatile. They are used in speech recognition, part-of-speech labeling, stock market prediction (ex: bull market vs. bear market states), and gene sequence analyses.\nIn event cognition literature, HMMs have been used as an event segmentation model, classifying event boundaries as time points where there is a transition from one stable brain state to another (see this paper).\nAdditionally, there are other methods for estimating HMM models such as the Baum-Welch algorithm which uses the EM combined with the forward-backward algorithm.\nPotentially useful R packages (which I am unfamiliar with) to fit HMM Models include:\n\ndepmixS4\nseqHMM\n\nIf you’re interested in depmixS4 this tutorial which goes through a simple example may be useful. The depmixs4 package by default uses the Baum-Welch algorithm to fit HMM models."
  },
  {
    "objectID": "posts/hmm/index.html#acknowledgements",
    "href": "posts/hmm/index.html#acknowledgements",
    "title": "Hidden Markov Modeling",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThanks to Shane Jensen whose lectures and code in STAT442 (Intro to Bayesian Data Analysis) I referenced in making this blog post."
  }
]